{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we tried to add an autoencoder to the Spherenet code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Linear, Embedding\n",
    "from torch_geometric.nn.inits import glorot_orthogonal\n",
    "from torch_geometric.nn import radius_graph\n",
    "from torch_scatter import scatter\n",
    "from math import sqrt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from dig.threedgraph.utils import xyz_to_dat\n",
    "from dig.threedgraph.method.spherenet.features import dist_emb, angle_emb, torsion_emb\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "class emb(torch.nn.Module):\n",
    "    def __init__(self, num_spherical, num_radial, cutoff, envelope_exponent):\n",
    "        super(emb, self).__init__()\n",
    "        self.dist_emb = dist_emb(num_radial, cutoff, envelope_exponent)\n",
    "        self.angle_emb = angle_emb(num_spherical, num_radial, cutoff, envelope_exponent)\n",
    "        self.torsion_emb = torsion_emb(num_spherical, num_radial, cutoff, envelope_exponent)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.dist_emb.reset_parameters()\n",
    "\n",
    "    def forward(self, dist, angle, torsion, idx_kj):\n",
    "        dist_emb = self.dist_emb(dist)\n",
    "        angle_emb = self.angle_emb(dist, angle, idx_kj)\n",
    "        torsion_emb = self.torsion_emb(dist, angle, torsion, idx_kj)\n",
    "        return dist_emb, angle_emb, torsion_emb\n",
    "\n",
    "class ResidualLayer(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, act=swish):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.act = act\n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot_orthogonal(self.lin1.weight, scale=2.0)\n",
    "        self.lin1.bias.data.fill_(0)\n",
    "        glorot_orthogonal(self.lin2.weight, scale=2.0)\n",
    "        self.lin2.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.act(self.lin2(self.act(self.lin1(x))))\n",
    "\n",
    "\n",
    "class init(torch.nn.Module):\n",
    "    def __init__(self, num_radial, hidden_channels, act=swish, use_node_features=True):\n",
    "        super(init, self).__init__()\n",
    "        self.act = act\n",
    "        self.use_node_features = use_node_features\n",
    "        if self.use_node_features:\n",
    "            self.emb = Embedding(95, hidden_channels)\n",
    "        else: # option to use no node features and a learned embedding vector for each node instead\n",
    "            self.node_embedding = nn.Parameter(torch.empty((hidden_channels,)))\n",
    "            nn.init.normal_(self.node_embedding)\n",
    "        self.lin_rbf_0 = Linear(num_radial, hidden_channels)\n",
    "        self.lin = Linear(3 * hidden_channels, hidden_channels)\n",
    "        self.lin_rbf_1 = nn.Linear(num_radial, hidden_channels, bias=False)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.use_node_features:\n",
    "            self.emb.weight.data.uniform_(-sqrt(3), sqrt(3))\n",
    "        self.lin_rbf_0.reset_parameters()\n",
    "        self.lin.reset_parameters()\n",
    "        glorot_orthogonal(self.lin_rbf_1.weight, scale=2.0)\n",
    "\n",
    "    def forward(self, x, emb, i, j):\n",
    "        rbf,_,_ = emb\n",
    "        if self.use_node_features:\n",
    "            x = self.emb(x)\n",
    "        else:\n",
    "            x = self.node_embedding[None, :].expand(x.shape[0], -1)\n",
    "        rbf0 = self.act(self.lin_rbf_0(rbf))\n",
    "        e1 = self.act(self.lin(torch.cat([x[i], x[j], rbf0], dim=-1)))\n",
    "        e2 = self.lin_rbf_1(rbf) * e1\n",
    "\n",
    "        return e1, e2\n",
    "\n",
    "\n",
    "class update_e(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, int_emb_size, basis_emb_size_dist, basis_emb_size_angle, basis_emb_size_torsion, num_spherical, num_radial,\n",
    "        num_before_skip, num_after_skip, act=swish):\n",
    "        super(update_e, self).__init__()\n",
    "        self.act = act\n",
    "        self.lin_rbf1 = nn.Linear(num_radial, basis_emb_size_dist, bias=False)\n",
    "        self.lin_rbf2 = nn.Linear(basis_emb_size_dist, hidden_channels, bias=False)\n",
    "        self.lin_sbf1 = nn.Linear(num_spherical * num_radial, basis_emb_size_angle, bias=False)\n",
    "        self.lin_sbf2 = nn.Linear(basis_emb_size_angle, int_emb_size, bias=False)\n",
    "        self.lin_t1 = nn.Linear(num_spherical * num_spherical * num_radial, basis_emb_size_torsion, bias=False)\n",
    "        self.lin_t2 = nn.Linear(basis_emb_size_torsion, int_emb_size, bias=False)\n",
    "        self.lin_rbf = nn.Linear(num_radial, hidden_channels, bias=False)\n",
    "\n",
    "        self.lin_kj = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.lin_ji = nn.Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.lin_down = nn.Linear(hidden_channels, int_emb_size, bias=False)\n",
    "        self.lin_up = nn.Linear(int_emb_size, hidden_channels, bias=False)\n",
    "\n",
    "        self.layers_before_skip = torch.nn.ModuleList([\n",
    "            ResidualLayer(hidden_channels, act)\n",
    "            for _ in range(num_before_skip)\n",
    "        ])\n",
    "        self.lin = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.layers_after_skip = torch.nn.ModuleList([\n",
    "            ResidualLayer(hidden_channels, act)\n",
    "            for _ in range(num_after_skip)\n",
    "        ])\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot_orthogonal(self.lin_rbf1.weight, scale=2.0)\n",
    "        glorot_orthogonal(self.lin_rbf2.weight, scale=2.0)\n",
    "        glorot_orthogonal(self.lin_sbf1.weight, scale=2.0)\n",
    "        glorot_orthogonal(self.lin_sbf2.weight, scale=2.0)\n",
    "        glorot_orthogonal(self.lin_t1.weight, scale=2.0)\n",
    "        glorot_orthogonal(self.lin_t2.weight, scale=2.0)\n",
    "\n",
    "        glorot_orthogonal(self.lin_kj.weight, scale=2.0)\n",
    "        self.lin_kj.bias.data.fill_(0)\n",
    "        glorot_orthogonal(self.lin_ji.weight, scale=2.0)\n",
    "        self.lin_ji.bias.data.fill_(0)\n",
    "\n",
    "        glorot_orthogonal(self.lin_down.weight, scale=2.0)\n",
    "        glorot_orthogonal(self.lin_up.weight, scale=2.0)\n",
    "\n",
    "        for res_layer in self.layers_before_skip:\n",
    "            res_layer.reset_parameters()\n",
    "        glorot_orthogonal(self.lin.weight, scale=2.0)\n",
    "        self.lin.bias.data.fill_(0)\n",
    "        for res_layer in self.layers_after_skip:\n",
    "            res_layer.reset_parameters()\n",
    "\n",
    "        glorot_orthogonal(self.lin_rbf.weight, scale=2.0)\n",
    "\n",
    "    def forward(self, x, emb, idx_kj, idx_ji):\n",
    "        rbf0, sbf, t = emb\n",
    "        x1,_ = x\n",
    "\n",
    "        x_ji = self.act(self.lin_ji(x1))\n",
    "        x_kj = self.act(self.lin_kj(x1))\n",
    "\n",
    "        rbf = self.lin_rbf1(rbf0)\n",
    "        rbf = self.lin_rbf2(rbf)\n",
    "        x_kj = x_kj * rbf\n",
    "\n",
    "        x_kj = self.act(self.lin_down(x_kj))\n",
    "\n",
    "        sbf = self.lin_sbf1(sbf)\n",
    "        sbf = self.lin_sbf2(sbf)\n",
    "        x_kj = x_kj[idx_kj] * sbf\n",
    "\n",
    "        t = self.lin_t1(t)\n",
    "        t = self.lin_t2(t)\n",
    "        x_kj = x_kj * t\n",
    "\n",
    "        x_kj = scatter(x_kj, idx_ji, dim=0, dim_size=x1.size(0))\n",
    "        x_kj = self.act(self.lin_up(x_kj))\n",
    "\n",
    "        e1 = x_ji + x_kj\n",
    "        for layer in self.layers_before_skip:\n",
    "            e1 = layer(e1)\n",
    "        e1 = self.act(self.lin(e1)) + x1\n",
    "        for layer in self.layers_after_skip:\n",
    "            e1 = layer(e1)\n",
    "        e2 = self.lin_rbf(rbf0) * e1\n",
    "\n",
    "        return e1, e2\n",
    "\n",
    "\n",
    "class update_v(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_emb_channels, out_channels, num_output_layers, act, output_init):\n",
    "        super(update_v, self).__init__()\n",
    "        self.act = act\n",
    "        self.output_init = output_init\n",
    "\n",
    "        self.lin_up = nn.Linear(hidden_channels, out_emb_channels, bias=True)\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        for _ in range(num_output_layers):\n",
    "            self.lins.append(nn.Linear(out_emb_channels, out_emb_channels))\n",
    "        self.lin = nn.Linear(out_emb_channels, out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot_orthogonal(self.lin_up.weight, scale=2.0)\n",
    "        for lin in self.lins:\n",
    "            glorot_orthogonal(lin.weight, scale=2.0)\n",
    "            lin.bias.data.fill_(0)\n",
    "        if self.output_init == 'zeros':\n",
    "            self.lin.weight.data.fill_(0)\n",
    "        if self.output_init == 'GlorotOrthogonal':\n",
    "            glorot_orthogonal(self.lin.weight, scale=2.0)\n",
    "\n",
    "    def forward(self, e, i):\n",
    "        _, e2 = e\n",
    "        v = scatter(e2, i, dim=0)\n",
    "        v = self.lin_up(v)\n",
    "        for lin in self.lins:\n",
    "            v = self.act(lin(v))\n",
    "        v = self.lin(v)\n",
    "        return v\n",
    "\n",
    "\n",
    "class update_u(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(update_u, self).__init__()\n",
    "\n",
    "    def forward(self, u, v, batch):\n",
    "        u += scatter(v, batch, dim=0)\n",
    "        return u\n",
    "\n",
    "\n",
    "class SphereNet(torch.nn.Module):\n",
    "    r\"\"\"\n",
    "         The spherical message passing neural network SphereNet from the `\"Spherical Message Passing for 3D Molecular Graphs\" <https://openreview.net/forum?id=givsRXsOt9r>`_ paper.\n",
    "        \n",
    "        Args:\n",
    "            energy_and_force (bool, optional): If set to :obj:`True`, will predict energy and take the negative of the derivative of the energy with respect to the atomic positions as predicted forces. (default: :obj:`False`)\n",
    "            cutoff (float, optional): Cutoff distance for interatomic interactions. (default: :obj:`5.0`)\n",
    "            num_layers (int, optional): Number of building blocks. (default: :obj:`4`)\n",
    "            hidden_channels (int, optional): Hidden embedding size. (default: :obj:`128`)\n",
    "            out_channels (int, optional): Size of each output sample. (default: :obj:`1`)\n",
    "            int_emb_size (int, optional): Embedding size used for interaction triplets. (default: :obj:`64`)\n",
    "            basis_emb_size_dist (int, optional): Embedding size used in the basis transformation of distance. (default: :obj:`8`)\n",
    "            basis_emb_size_angle (int, optional): Embedding size used in the basis transformation of angle. (default: :obj:`8`)\n",
    "            basis_emb_size_torsion (int, optional): Embedding size used in the basis transformation of torsion. (default: :obj:`8`)\n",
    "            out_emb_channels (int, optional): Embedding size used for atoms in the output block. (default: :obj:`256`)\n",
    "            num_spherical (int, optional): Number of spherical harmonics. (default: :obj:`7`)\n",
    "            num_radial (int, optional): Number of radial basis functions. (default: :obj:`6`)\n",
    "            envelop_exponent (int, optional): Shape of the smooth cutoff. (default: :obj:`5`)\n",
    "            num_before_skip (int, optional): Number of residual layers in the interaction blocks before the skip connection. (default: :obj:`1`)\n",
    "            num_after_skip (int, optional): Number of residual layers in the interaction blocks before the skip connection. (default: :obj:`2`)\n",
    "            num_output_layers (int, optional): Number of linear layers for the output blocks. (default: :obj:`3`)\n",
    "            act: (function, optional): The activation funtion. (default: :obj:`swish`)\n",
    "            output_init: (str, optional): The initialization fot the output. It could be :obj:`GlorotOrthogonal` and :obj:`zeros`. (default: :obj:`GlorotOrthogonal`)\n",
    "            \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, energy_and_force=False, cutoff=5.0, num_layers=4,\n",
    "        hidden_channels=128, out_channels=1, int_emb_size=64,\n",
    "        basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256,\n",
    "        num_spherical=7, num_radial=6, envelope_exponent=5,\n",
    "        num_before_skip=1, num_after_skip=2, num_output_layers=3,\n",
    "        act=swish, output_init='GlorotOrthogonal', use_node_features=True):\n",
    "        super(SphereNet, self).__init__()\n",
    "\n",
    "        self.cutoff = cutoff\n",
    "        self.energy_and_force = energy_and_force\n",
    "        \n",
    "        self.edge_emb_size = 12\n",
    "        self.init_e = init(num_radial, hidden_channels, act, use_node_features=use_node_features)\n",
    "        self.init_v = update_v(hidden_channels, out_emb_channels, out_channels, num_output_layers, act, output_init)\n",
    "        self.init_u = update_u()\n",
    "        self.emb = emb(num_spherical, num_radial, self.cutoff, envelope_exponent)\n",
    "\n",
    "        self.update_vs = torch.nn.ModuleList([\n",
    "            update_v(hidden_channels, out_emb_channels, out_channels, num_output_layers, act, output_init) for _ in range(num_layers)])\n",
    "\n",
    "        self.update_es = torch.nn.ModuleList([\n",
    "            update_e(hidden_channels, int_emb_size, basis_emb_size_dist, basis_emb_size_angle, basis_emb_size_torsion, num_spherical, num_radial, num_before_skip, num_after_skip,act) for _ in range(num_layers)])\n",
    "\n",
    "        self.update_us = torch.nn.ModuleList([update_u() for _ in range(num_layers)])\n",
    "\n",
    "        # Autoencoder layers\n",
    "        ae_hidden_channels = 16\n",
    "        ae_latent_channels = 8\n",
    "        self.ae_encoder = nn.Sequential(\n",
    "            nn.Linear(out_emb_channels + hidden_channels + out_channels, ae_hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ae_hidden_channels, ae_latent_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.ae_decoder = nn.Sequential(\n",
    "            nn.Linear(ae_latent_channels, ae_hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ae_hidden_channels, out_emb_channels + hidden_channels + out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Torsion, distance, and angle decoder layers\n",
    "        self.torsion_decoder = nn.Sequential(\n",
    "            nn.Linear(ae_latent_channels, basis_emb_size_torsion),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(basis_emb_size_torsion, num_spherical)\n",
    "        )\n",
    "        self.distance_decoder = nn.Sequential(\n",
    "            nn.Linear(ae_latent_channels, basis_emb_size_dist),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(basis_emb_size_dist, num_radial)\n",
    "        )\n",
    "        self.angle_decoder = nn.Sequential(\n",
    "            nn.Linear(ae_latent_channels, basis_emb_size_angle),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(basis_emb_size_angle, num_spherical)\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.init_e.reset_parameters()\n",
    "        self.init_v.reset_parameters()\n",
    "        self.emb.reset_parameters()\n",
    "        for update_e in self.update_es:\n",
    "            update_e.reset_parameters()\n",
    "        for update_v in self.update_vs:\n",
    "            update_v.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, batch_data):\n",
    "        z, pos, batch = batch_data.z, batch_data.pos, batch_data.batch\n",
    "        if self.energy_and_force:\n",
    "            pos.requires_grad_()\n",
    "        edge_index = radius_graph(pos, r=self.cutoff, batch=batch)\n",
    "        num_nodes=z.size(0)\n",
    "        dist, angle, torsion, i, j, idx_kj, idx_ji = xyz_to_dat(pos, edge_index, num_nodes, use_torsion=True)\n",
    "\n",
    "        emb = self.emb(dist, angle, torsion, idx_kj)\n",
    "        \n",
    "        #Initialize edge, node, graph features\n",
    "        e = self.init_e(z, emb, i, j)\n",
    "        v = self.init_v(e, i)\n",
    "        u = self.init_u(torch.zeros_like(scatter(v, batch, dim=0)), v, batch) #scatter(v, batch, dim=0)\n",
    "\n",
    "        for update_e, update_v, update_u in zip(self.update_es, self.update_vs, self.update_us):\n",
    "            e = update_e(e, emb, idx_kj, idx_ji)\n",
    "            v = update_v(e, i)\n",
    "            u = update_u(u, v, batch) #u += scatter(v, batch, dim=0)\n",
    "        \n",
    "        # Pass e, v, u through the autoencoder\n",
    "        edge_emb = self.edge_embedding(batch.edge_index)\n",
    "        ae_input = torch.cat([e, v, u, edge_emb], dim=1)\n",
    "        ae_latent = self.ae_encoder(ae_input)\n",
    "        ae_output = self.ae_decoder(ae_latent)\n",
    "\n",
    "        # Decode torsion, distance, and angle\n",
    "        torsion = self.torsion_decoder(ae_latent)\n",
    "        distance = self.distance_decoder(ae_latent)\n",
    "        angle = self.angle_decoder(ae_latent)\n",
    "\n",
    "        \n",
    "        return torsion, distance, angle\n",
    "    def calculate_reconstruction_loss(input_features, reconstructed_features):\n",
    "        reconstruction_loss = F.mse_loss(reconstructed_features, input_features)\n",
    "        return reconstruction_loss\n",
    "\n",
    "    def calculate_kl_loss(mu, logvar):\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return kl_loss\n",
    "\n",
    "    def calculate_total_loss(input_features, reconstructed_features, mu, logvar, lambda_kl):\n",
    "        reconstruction_loss = calculate_reconstruction_loss(input_features, reconstructed_features)\n",
    "        kl_loss = calculate_kl_loss(mu, logvar)\n",
    "        total_loss = reconstruction_loss + lambda_kl * kl_loss\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dig.threedgraph.utils.geometric_computing import xyz_to_dat\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from Project.data_process.qm9_process import qm9_data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../../../others_approaches/conformation_generation/GeoMol/data/QM9/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_set = qm9_data(root= path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "data0 = qm9_set[6]\n",
    "print(len(qm9_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "z, pos, batch = data0.z, data0.pos, data0\n",
    "\n",
    "num_nodes=z.size(0)\n",
    "print(num_nodes)\n",
    "dist, angle, torsion, i, j, idx_kj, idx_ji = xyz_to_dat(pos, data0.edge_index, num_nodes, use_torsion=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spherical_to_xyz(dist, angle, torsion, edge_index, idx_kj, idx_ji, pos):\n",
    "    '''\n",
    "    This function is to reverse the spherical coordinates to cartesian coordinates\n",
    "    it is only used for the purpose of loss calculations in the model. It takes the\n",
    "    position of the 0 atom as an input and starts building the graph from there.\n",
    "    @inputs:\n",
    "        dist: is the distance matrix between the connected atoms.\n",
    "        angle: the angle between 2 consecutive bonds\n",
    "        torsion: the torsion angle of a bond\n",
    "        edge_index: is the edge index matrix\n",
    "        idx_kj: The first bond index from the edge index matrix. \n",
    "        idx_ji: The second bond index form the edge index matrix.\n",
    "        pos: The crtesian position of all atoms. \n",
    "    '''\n",
    "\n",
    "    # Retrieve the indices from edge_index\n",
    "    j, i = edge_index\n",
    "\n",
    "    # Create empty tensors to store the cartesian positions\n",
    "    xyz_pos = torch.zeros_like(pos)\n",
    "\n",
    "    # Set the position of the 0th atom\n",
    "    xyz_pos[0] = pos[0]\n",
    "\n",
    "    # Iterate over the remaining atoms and calculate their positions\n",
    "    for k in range(1, pos.size(0)):\n",
    "        # Calculate the unit vectors for each bond\n",
    "        v_ji = pos[i[k]] - pos[j[k]]  # Vector from j to i\n",
    "        v_kj = pos[j[k]] - pos[k]  # Vector from k to j\n",
    "\n",
    "        # Calculate the normalized vectors\n",
    "        u_ji = v_ji / dist[k]  # Unit vector from j to i\n",
    "        u_kj = v_kj / dist[k]  # Unit vector from k to j\n",
    "\n",
    "        # Calculate the new position based on the spherical coordinates\n",
    "        xyz_pos[k] = xyz_pos[j[k]] + dist[k] * (torch.cos(angle[k]) * u_ji + torch.sin(angle[k]) * torch.cross(u_kj, u_ji))\n",
    "\n",
    "    return xyz_pos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = qm9_set.get_idx_split(len(qm9_set.data.y), train_size=300, valid_size=100, seed=42)\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = qm9_set[split_idx['train']], qm9_set[split_idx['valid']], qm9_set[split_idx['test']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SphereNet(energy_and_force=False, cutoff=5.0, num_layers=4, \n",
    "        hidden_channels=128, out_channels=1, int_emb_size=64, \n",
    "        basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=256, \n",
    "        num_spherical=3, num_radial=6, envelope_exponent=5, \n",
    "        num_before_skip=1, num_after_skip=2, num_output_layers=3, use_node_features=True\n",
    "        )\n",
    "\n",
    "# Choose an optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(2):\n",
    "    for batch_data, edge_index, target_torsion, target_distance, target_angle in train_dataloader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        predicted_torsion, predicted_distance, predicted_angle = model(batch_data, edge_index)\n",
    "        \n",
    "        # Calculate the losses\n",
    "        reconstruction_loss = model.calculate_reconstruction_loss(input_features, reconstructed_features)\n",
    "        kl_loss = model.calculate_kl_loss(mu, logvar)\n",
    "        total_loss = model.calculate_total_loss(input_features, reconstructed_features, mu, logvar, lambda_kl)\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Print the loss for this epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_data, edge_index, target_torsion, target_distance, target_angle in validation_dataloader:\n",
    "        predicted_torsion, predicted_distance, predicted_angle = model(batch_data, edge_index)\n",
    "        # Calculate and print evaluation metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DIG-Stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Mar  2 2023, 03:21:46) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7cfb14014bc05b7b9c111b7cecf146c136c646b654c64df2272ca310a47a6635"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
